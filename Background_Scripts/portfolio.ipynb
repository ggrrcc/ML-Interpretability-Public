{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# a = pd.DataFrame(data={'a':[1,1,2,2,3,3], 'b':[5,6,7,8,9,0], 'c':[0,0,0,0,0,0], 'cc':[0,0,0,0,0,0], 'ccc':[0,0,0,0,0,0]})\n",
    "# q = ['cc', 'ccc']\n",
    "# print(q + (['a', 'c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.loc[a['a'].isin([1,3])][['a', 'c'] + q]\n",
    "# current_df.loc[current_df['permno'] ==jj][['permno']+features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio():\n",
    "    def __init__(\n",
    "            self, signal_set = [[]], stock_set = [[]], strategy = 0, missing_signal = -1,\n",
    "            merged_data = pd.DataFrame(), merged_data_train = pd.DataFrame(), merged_data_test = pd.DataFrame()\n",
    "            ):\n",
    "        assert type(signal_set) == list\n",
    "        assert type(stock_set) == list\n",
    "\n",
    "        self.signal_set = signal_set\n",
    "        self.stock_set = stock_set\n",
    "        self.merged_data = merged_data.sort_values(by=['date', 'permno'])\n",
    "        self.data_train = merged_data_train.sort_values(by=['date', 'permno'])\n",
    "        self.data_test = merged_data_test.sort_values(by=['date', 'permno'])\n",
    "\n",
    "        self.model_lol = self.model_creation()\n",
    "\n",
    "        self.current_holdings = pd.DataFrame(columns=['permno', 'per_dollar_amount'])\n",
    "        self.prev_trades = pd.DataFrame(columns=['date_open', 'date_close', 'permno', 'per_dollar_amount_open', 'per_dollar_amount_close', 'num_shares', 'PRC_open', 'PRC_close', 'P&L'])\n",
    "        self.strategy_info = strategy_info\n",
    "        self.missing_signal = missing_signal\n",
    "        self.output_folder_path = self.make_backtest_path(strategy_info['output folder name'], strategy)\n",
    "        self.trades = pd.DataFrame()\n",
    "        self.nav_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    def model_creation(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        model_lol = []\n",
    "        for si in self.signal_set:\n",
    "            model_list = []\n",
    "            features = []\n",
    "            for key in si:\n",
    "                features = features + signal_label_dict[key]\n",
    "\n",
    "            X_train = self.data_train[['date', 'permno'] + features]\n",
    "            for st in self.stock_set:\n",
    "                subset_X_train = X_train[X_train['permno'].isin(st)]\n",
    "\n",
    "                # TODO: Check to see if necessary to add in extra 'permnos'\n",
    "                # edited_data = self.data_train[self.data_train['permno'].isin(st)][['date', 'permno'] + si + features]\n",
    "                # # Convert 'date' column to datetime if not already\n",
    "                # edited_data['date'] = pd.to_datetime(edited_data['date'])\n",
    "                # # Option 2: Convert to days since a particular reference date (e.g., the first date in your dataset)\n",
    "                # ref_date = edited_data['date'].min()\n",
    "                # edited_data['date_numeric'] = (edited_data['date'] - ref_date).dt.days\n",
    "                # X_train = edited_data[['date_numeric', 'permno'] + features]\n",
    "                \n",
    "                # I think the following two lines can be made more efficient\n",
    "                y = self.data_train[self.data_train['permno'].isin(st)]\n",
    "                y_train = label_encoder.fit_transform(y[si])\n",
    "\n",
    "                curr_model = RandomForestClassifier(n_estimators=50, random_state=42)#, warm_start=True)\n",
    "                curr_model.fit(subset_X_train, y_train)\n",
    "                model_list.append(curr_model)\n",
    "            model_lol.append(model_list)\n",
    "        return model_lol\n",
    "\n",
    "    def model_access(self, og_X_test):\n",
    "        edited_data = og_X_test[:][:]\n",
    "        # Convert 'date' column to datetime if not already\n",
    "        edited_data['date_old'] = pd.to_datetime(edited_data['date'])\n",
    "        # Option 2: Convert to days since a particular reference date (e.g., the first date in your dataset)\n",
    "        internal_ref_date = edited_data['date_old'].min()\n",
    "        edited_data['date'] = (edited_data['date_old'] - internal_ref_date).dt.days\n",
    "        curr_pred = []\n",
    "        i = 0\n",
    "\n",
    "        for si in self.signal_set:\n",
    "            \n",
    "            features = []\n",
    "            for key in si:\n",
    "                features = features + signal_label_dict[key]\n",
    "            X_test = edited_data[['date', 'permno'] + features]\n",
    "            sig_pred = []\n",
    "            j = 0\n",
    "            for st in self.stock_set:\n",
    "                subset_X_test = X_test[X_test['permno'].isin(st)]\n",
    "                if len(subset_X_test) == 0:\n",
    "                    sig_pred.append(np.array([1]*len(si))/len(self.signal_set))\n",
    "                else:\n",
    "                    curr_model = self.model_lol[i][j]\n",
    "                    pred = curr_model.predict(subset_X_test)\n",
    "                    sig_pred.append(pred/len(self.signal_set))\n",
    "                j += 1\n",
    " \n",
    "            curr_pred.append(sig_pred)\n",
    "            i += 1\n",
    "\n",
    "        summed_array = [0]*num_stocks\n",
    "        ind = 0\n",
    "        for i in curr_pred:\n",
    "            for j in i:\n",
    "                for k in j:\n",
    "                    summed_array[ind%num_stocks] += float(k)\n",
    "                    ind += 1\n",
    "        res = [1 if x > 4/3 else -1 if x < 2/3 else 0 for x in summed_array]\n",
    "        return res # This prediction is for all stocks for that day\n",
    "    \n",
    "    def compute_trades(self, start_date = -1, end_date = -1):\n",
    "        # If computing all trades in the testing dataset\n",
    "        if start_date == -1 and end_date == -1:\n",
    "            total_test_set = self.data_test\n",
    "        else:\n",
    "            total_test_set = self.data_test[(self.data_test['date'] >= start_date) & (self.data_test['date'] < end_date)]\n",
    "        for date in trading_dates:\n",
    "            curr_test_set = total_test_set[total_test_set['date']==date]\n",
    "            curr_pred = self.model_access(curr_test_set)\n",
    "            if any(x != 0 for x in curr_pred):\n",
    "                num_buys = sum(1 for x in curr_pred if x > 0)\n",
    "                num_sells = sum(1 for x in curr_pred if x < 0)\n",
    "                \n",
    "                for permno_ind in range(len(curr_pred)):\n",
    "                    if curr_pred[permno_ind] > 0 and num_buys > 0:\n",
    "                        new_row = {'date_open': date, 'permno':stocks_og[permno_ind], 'per_dollar_amount_open':1.0/num_buys}\n",
    "                    elif curr_pred[permno_ind] < 0 and num_sells > 0:\n",
    "                        new_row = {'date_open': date, 'permno':stocks_og[permno_ind], 'per_dollar_amount_open':-1.0/num_sells*.5}\n",
    "                    else:\n",
    "                        continue\n",
    "                    self.prev_trades.loc[len(self.prev_trades)] = new_row\n",
    "        self.trades = self.prev_trades\n",
    "        \n",
    "    def execute_trades(self, starting_nav=100):\n",
    "        # Ensure the dataframes are sorted by date (ascending)\n",
    "        prices_df = self.data_test[['date', 'permno', 'PRC']].copy()\n",
    "        trades_df = self.prev_trades[:][:]\n",
    "        new_trades_df = pd.merge(trades_df, prices_df, left_on=['date_open', 'permno'], right_on=['date', 'permno'], how='left')\n",
    "        new_trades_df['PRC_open'] = new_trades_df['PRC']\n",
    "        new_trades_df.drop(['PRC', 'date'], axis=1, inplace=True)\n",
    "        new_trades_df['date_close'] = new_trades_df['date_open'].map(next_day_map)\n",
    "        new_trades_df = pd.merge(new_trades_df, prices_df, left_on=['date_close', 'permno'], right_on=['date', 'permno'], how='left')\n",
    "        new_trades_df['PRC_close'] = new_trades_df['PRC']\n",
    "        new_trades_df.drop(['PRC', 'date'], axis=1, inplace=True)\n",
    "\n",
    "        nav = starting_nav\n",
    "        nav_list = [nav]\n",
    "        nav_df = pd.DataFrame(columns=['date', 'nav']).set_index('date')\n",
    "        for date in trading_dates:\n",
    "            current_df = new_trades_df[new_trades_df['date_close']==date]\n",
    "\n",
    "            current_df.loc[:,'num_shares'] = current_df.loc[:,'per_dollar_amount_open']/current_df.loc[:,'PRC_open']*nav_list[-1]\n",
    "            current_df.loc[:,'per_dollar_amount_close'] = current_df.loc[:,'PRC_close']*current_df.loc[:,'num_shares']/nav_list[-1]\n",
    "            current_df.loc[:,'P&L'] = (current_df.loc[:,'per_dollar_amount_close'] - current_df.loc[:,'per_dollar_amount_open'])*nav_list[-1]\n",
    "            # then figure out quantities and shit\n",
    "\n",
    "            nav_list.append(nav_list[-1] + sum(current_df['P&L']))\n",
    "            nav_df.loc[date,'nav'] = nav_list[-1]\n",
    "\n",
    "        self.nav_df = nav_df\n",
    "        # Plot the NAV over time\n",
    "        # self.nav_plot()\n",
    "        # return nav_df\n",
    "\n",
    "    # Outputs statistics and plots to files\n",
    "    def output_stats(self):               \n",
    "        \n",
    "        # Output full csvs for account_history and trades\n",
    "        self.nav_df.to_csv( self.output_folder_path / 'account_history.csv' )\n",
    "        self.trades.to_csv( self.output_folder_path / 'trades.csv' )\n",
    "        \n",
    "        # Compute and output main stats, which will go in this dictionary\n",
    "        backtest_stats = dict()\n",
    "        \n",
    "        # Get the return series from the account history\n",
    "        ret_series = self.nav_df.loc[:,'nav'].pct_change().dropna().reset_index(drop=True)\n",
    "        \n",
    "        # Number of periods per year for annualization\n",
    "        N = self.strategy_info['periods per year']\n",
    "        \n",
    "        # means\n",
    "        backtest_stats['arith mean'] = ret_series.mean()\n",
    "        backtest_stats['arith mean (ann)'] = ret_series.mean()*N\n",
    "        backtest_stats['geomean mean'] = stats.gmean(1+ret_series)-1\n",
    "        backtest_stats['geomean mean (ann)'] = stats.gmean(1+ret_series)**N-1\n",
    "        \n",
    "        # risks\n",
    "        backtest_stats['sigma'] = ret_series.std()\n",
    "        backtest_stats['sigma (ann)'] = ret_series.std()*(N**0.5)\n",
    "        drawdown = 1-self.nav_df.loc[:,'nav'] / self.nav_df.loc[:,'nav'].cummax()\n",
    "        backtest_stats['avg drawdown'] = drawdown.mean()\n",
    "        backtest_stats['max drawdown'] = drawdown.max()\n",
    "        \n",
    "        # alpha/beta\n",
    "        mkt_rf_df = pd.read_csv(market_data_path)\n",
    "        mkt_rf_df.loc[:,'date1'] = mkt_rf_df['date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "        mkt_rf_df['date'] = mkt_rf_df['date1']\n",
    "        del mkt_rf_df['date1']\n",
    "        mkt_rf_df['int_date'] = (mkt_rf_df['date'] - ref_date).dt.days\n",
    "        mkt_rf_df = mkt_rf_df.loc[mkt_rf_df.loc[:,'int_date'].isin(self.nav_df.index),:]\n",
    "        mkt_series = mkt_rf_df.loc[:,'mkt_index'].pct_change().dropna().reset_index(drop=True)\n",
    "        rf_series = mkt_rf_df.loc[:,'rf_index'].pct_change().dropna().reset_index(drop=True)\n",
    "        \n",
    "        # Set up left- and right-hand sides for regressions\n",
    "        lhs = ret_series\n",
    "        rhs = sm.add_constant( mkt_series - rf_series )\n",
    "        \n",
    "        # Run the regression \n",
    "        model = sm.OLS(lhs,rhs) \n",
    "        results = model.fit()\n",
    "        \n",
    "        # extract alpha and beta\n",
    "        backtest_stats['alpha'] = results.params['const']\n",
    "        backtest_stats['alpha SE'] = results.bse['const']\n",
    "        backtest_stats['alpha (ann)'] = results.params['const']*N\n",
    "        backtest_stats['alpha SE (ann)'] = results.bse['const']*N\n",
    "        backtest_stats['beta'] = results.params[0]\n",
    "        backtest_stats['betaSE'] = results.bse[0]        \n",
    "        \n",
    "        # ratios        \n",
    "        backtest_stats['Sharpe ratio'] = backtest_stats['arith mean'] / backtest_stats['sigma']\n",
    "        backtest_stats['Sharpe ratio (ann)'] = backtest_stats['arith mean (ann)'] / backtest_stats['sigma (ann)']\n",
    "        backtest_stats['information ratio'] = backtest_stats['alpha'] / backtest_stats['sigma']\n",
    "        backtest_stats['information ratio (ann)'] = backtest_stats['alpha (ann)'] / backtest_stats['sigma (ann)']\n",
    "        \n",
    "        # Turn into a dataframe and output as csv\n",
    "        pd.DataFrame.from_dict(data=backtest_stats, orient='index').to_csv(self.output_folder_path / 'backtest_stats.csv')\n",
    "        \n",
    "        self.nav_plot()\n",
    "        \n",
    "    # Make and output the cumulative NAV history plot    \n",
    "    def nav_plot(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.nav_df.index, self.nav_df['nav'], label='NAV', color='blue')\n",
    "        plt.title('Net Asset Value (NAV) Over Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('NAV ($)')\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # plt.style.use('default')  # set plot style to 'default' \n",
    "\n",
    "        # # Standard set-up for a matplotlib plot\n",
    "        # fig = plt.figure() # this will automatically show the most updated version of the plot after you run the cell, so no need to have a \"fig\" line later again\n",
    "        # ax = fig.add_subplot(1,1,1)\n",
    "        # fig.suptitle(list_of_models[i])\n",
    "        # plotdates = self.portfolio_db.account_history_df.loc[:,'datetime']\n",
    "        # ax.plot(plotdates, self.portfolio_db.account_history_df.loc[:,'nav'] / self.portfolio_db.account_history_df.loc[:,'nav'].iloc[0]) \n",
    "        \n",
    "        # # Customize the plot properties\n",
    "        # ax.set_xlabel('Date')\n",
    "        # ax.set_yscale('log')\n",
    "        # ax.yaxis.set_major_locator( ticker.LogLocator(base=2) )        \n",
    "        # ax.yaxis.set_minor_locator( ticker.LogLocator(base=2, subs=[1.25, 1.5, 1.75]))\n",
    "        # ax.yaxis.set_major_formatter( ticker.ScalarFormatter() )\n",
    "        # ax.yaxis.set_minor_formatter( ticker.NullFormatter() )\n",
    "        # ax.set_ylabel(self.strategy_info['plot descriptor'])\n",
    "        # ax.set_xlim(plotdates.min(), plotdates.max())\n",
    "        # ax.xaxis.set_major_formatter( mdates.DateFormatter('%Y'))  # format the tick labels using years\n",
    "        \n",
    "        # Save in our folder\n",
    "        plt.savefig(self.output_folder_path / 'nav_plot.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "    # Create the path object for the folder used for the backtest output\n",
    "    # The folder name will look like YYYYmmddHHMm/stratname_strategy/Num_missing_signal\n",
    "    def make_backtest_path(self, output_folder, strategy=0):\n",
    "        output_path = Path(output_folder) \n",
    "        \n",
    "        # This is the output name we want\n",
    "        folder_name = '{0}_{1}'.format(self.strategy_info['brief descriptor'], missing_signal)\n",
    "        self.output_folder_path = Path(output_path / time_date / str(strategy), folder_name)  \n",
    "    \n",
    "        # It's possible the folder already exists, if it does add a ' (1)' or ' (2)' or however high we need to go\n",
    "        # This follows the Windows convention for duplicate files\n",
    "        num_attempts = 1\n",
    "        while( self.output_folder_path.exists() ):\n",
    "            folder_name_conflict = folder_name + ' ({0})'.format(num_attempts)\n",
    "            self.output_folder_path = Path(output_path / time_date / str(strategy) / folder_name_conflict)  \n",
    "            num_attempts += 1\n",
    "            \n",
    "        self.output_folder_path.mkdir(parents=True)\n",
    "        \n",
    "        return self.output_folder_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
